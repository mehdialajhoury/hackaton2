# Hackaton 2

Ce projet impl√©mente un **pipeline automatis√© de contenu GenAI** (*Generative AI Content Pipeline*). Il permet de g√©n√©rer du texte, de le r√©sumer, d'en √©valuer la qualit√© automatiquement et de filtrer les contenus √©thiquement douteux. Le script effectue une analyse comparative (benchmark) de diff√©rentes combinaisons de mod√®les l√©gers adapt√©s aux ressources CPU.

---

## üìã Contexte du Projet

Ce projet r√©pond au d√©fi **"Generative AI Content Pipeline With Workflow Automation"**.

### Objectif Global
Construire un pipeline de bout en bout qui :
1.  G√©n√®re du texte ou des images.
2.  V√©rifie la qualit√© du contenu.
3.  Applique un filtrage √©thique.
4.  Fonctionne sur des ressources modestes (CPU).

### Workflow Impl√©ment√©
1.  **Prompt :** Extrait du dataset IMDB.
2.  **G√©n√©ration :** Utilisation de mod√®les Transformers l√©gers (`distilgpt2`, `t5-small`).
3.  **Contr√¥le Qualit√© :** R√©sum√© automatique + V√©rification s√©mantique.
4.  **Filtre √âthique :** D√©tection de mots-cl√©s interdits.
5.  **Output :** Visualisation graphique des performances (Temps vs Qualit√©).

---

## ‚öôÔ∏è Architecture Technique

Le script `main.py` ex√©cute une **analyse comparative** de 6 combinaisons de mod√®les diff√©rentes.

### 1. Mod√®les Utilis√©s
Le code teste toutes les permutations entre :
* **G√©n√©ration (Gen) :** `distilgpt2`, `t5-small`, `google/flan-t5-small`
* **R√©sum√© (Sum) :** `t5-small`, `google/flan-t5-small`

### 2. Pipeline de Traitement (`MultiModelPipeline`)
Pour chaque item, le pipeline suit ces √©tapes :

1.  **G√©n√©ration Adaptative :** D√©tection automatique du type de t√¢che (`text-generation` ou `text2text-generation`) selon le mod√®le.
2.  **R√©sum√© Automatique :** Synth√®se du texte g√©n√©r√© pour v√©rification.
3.  **M√©triques de Qualit√© (Auto-Eval) :**
    * **S√©mantique :** Calcul de similarit√© cosinus entre le *Prompt* et le *R√©sum√©* via `SentenceTransformer` (`all-MiniLM-L6-v2`).
    * **Diversit√© :** Ratio de mots uniques pour √©viter les r√©p√©titions en boucle.
    * **Longueur :** V√©rification de la consistance du texte.
4.  **Filtre √âthique :** Rejet si pr√©sence de mots bannis (ex: "hate", "violence").

---

## üöÄ Installation et D√©marrage

### Pr√©requis
* Python 3.8 ou sup√©rieur
* Connexion Internet (pour le t√©l√©chargement initial des mod√®les Hugging Face)

### Installation des d√©pendances

```bash
pip install torch transformers sentence-transformers datasets matplotlib numpy scikit-learn

## üë• Auteurs

Mehdi Al-Ajhoury Emmanuel Mussche
